{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5900624-58b2-46c3-a018-55853ecf5d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb12acc8-084e-4ed9-a7dd-ad7a061da360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas:  2.1.0\n",
      "seaborn:  0.12.2\n"
     ]
    }
   ],
   "source": [
    "print(\"pandas: \", pd.__version__)\n",
    "print(\"seaborn: \",sns.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02f687e-9263-4772-bb35-6e85d7630515",
   "metadata": {},
   "source": [
    "# Ler microdados do ENEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3ab48-e176-467d-95d7-f2058856c977",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Selecionar apenas uma amostra aleatória de 1% dos alunos\n",
    "Se a gente lê o arquivo de 3GB inteiro, vai dar problema. Aqui tem uma receita para ler somente x%: https://www.kaggle.com/questions-and-answers/53925 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f88346e-dada-4c5a-be4b-9385515b545b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, True, True, True, True, True, True, True, True]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def skip(i,fraction=0.01):\n",
    "    if i == 0:\n",
    "        return False  # precisamos manter o row=0 para ter o header\n",
    "    else:\n",
    "        return random.random() > fraction\n",
    "\n",
    "[skip(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8658a5-0379-4576-b6bf-a2785633535e",
   "metadata": {},
   "source": [
    "A título de exemplo, vamos carregar os dados de 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5b91cb9-7ffc-446e-b026-429f1554c59b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.8 s, sys: 1.33 s, total: 20.1 s\n",
      "Wall time: 20.1 s\n"
     ]
    }
   ],
   "source": [
    "%time df = pd.read_csv('../inep/enem/2010/DADOS/MICRODADOS_ENEM_2010.csv',skiprows = skip, encoding='latin1',sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66a713dd-6e11-450b-94fe-21235815a830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_INSCRICAO</th>\n",
       "      <th>NU_ANO</th>\n",
       "      <th>TP_FAIXA_ETARIA</th>\n",
       "      <th>TP_SEXO</th>\n",
       "      <th>TP_ESTADO_CIVIL</th>\n",
       "      <th>TP_COR_RACA</th>\n",
       "      <th>TP_ST_CONCLUSAO</th>\n",
       "      <th>TP_ENSINO</th>\n",
       "      <th>CO_MUNICIPIO_ESC</th>\n",
       "      <th>NO_MUNICIPIO_ESC</th>\n",
       "      <th>...</th>\n",
       "      <th>Q48</th>\n",
       "      <th>Q49</th>\n",
       "      <th>Q50</th>\n",
       "      <th>Q51</th>\n",
       "      <th>Q52</th>\n",
       "      <th>Q53</th>\n",
       "      <th>Q54</th>\n",
       "      <th>Q55</th>\n",
       "      <th>Q56</th>\n",
       "      <th>Q57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000000068</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200000000111</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200000000231</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200000000356</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200000000439</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2304400.0</td>\n",
       "      <td>FORTALEZA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45824</th>\n",
       "      <td>200004611062</td>\n",
       "      <td>2010</td>\n",
       "      <td>15</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45825</th>\n",
       "      <td>200004611079</td>\n",
       "      <td>2010</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45826</th>\n",
       "      <td>200004611170</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45827</th>\n",
       "      <td>200004611412</td>\n",
       "      <td>2010</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45828</th>\n",
       "      <td>200004611477</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45829 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NU_INSCRICAO  NU_ANO  TP_FAIXA_ETARIA TP_SEXO  TP_ESTADO_CIVIL  \\\n",
       "0      200000000068    2010               12       M                1   \n",
       "1      200000000111    2010                5       M                0   \n",
       "2      200000000231    2010                4       F                0   \n",
       "3      200000000356    2010               11       F                0   \n",
       "4      200000000439    2010                4       F                0   \n",
       "...             ...     ...              ...     ...              ...   \n",
       "45824  200004611062    2010               15       F                0   \n",
       "45825  200004611079    2010               14       F                1   \n",
       "45826  200004611170    2010                6       F                0   \n",
       "45827  200004611412    2010               14       F                0   \n",
       "45828  200004611477    2010               11       M                0   \n",
       "\n",
       "       TP_COR_RACA  TP_ST_CONCLUSAO  TP_ENSINO  CO_MUNICIPIO_ESC  \\\n",
       "0                1                1        2.0               NaN   \n",
       "1                3                1        1.0               NaN   \n",
       "2                3                1        1.0               NaN   \n",
       "3                3                1        1.0               NaN   \n",
       "4                1                2        1.0         2304400.0   \n",
       "...            ...              ...        ...               ...   \n",
       "45824            3                1        1.0               NaN   \n",
       "45825            2                1        3.0               NaN   \n",
       "45826            4                1        1.0               NaN   \n",
       "45827            2                1        1.0               NaN   \n",
       "45828            0                3        NaN               NaN   \n",
       "\n",
       "      NO_MUNICIPIO_ESC  ...  Q48  Q49  Q50  Q51  Q52  Q53  Q54  Q55  Q56  Q57  \n",
       "0                  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1                  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2                  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3                  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4            FORTALEZA  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "...                ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "45824              NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "45825              NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "45826              NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "45827              NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "45828              NaN  ...  3.0  0.0  0.0  0.0  0.0    D  5.0  5.0  5.0  5.0  \n",
       "\n",
       "[45829 rows x 105 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b6590a-355d-4bd1-bb57-157708954322",
   "metadata": {},
   "source": [
    "De fato, só vem 50 mil linhas (os dados originais devem conter da ordem de 3-6 milhões de participantes)\n",
    "\n",
    "Em seguinda, vamos filtrar estes dados pela presença na prova, se é treineiro e estar concluindo o EM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b363577-b651-48f7-8576-a50382cc9ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TP_PRESENCA_CN\n",
       "1.0    33472\n",
       "0.0    12306\n",
       "2.0       50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"TP_PRESENCA_CN\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db52d0ee-b8fa-44f1-97bf-2a2a59368663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TP_ST_CONCLUSAO\n",
       "1    26858\n",
       "2    13680\n",
       "3     5291\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TP_ST_CONCLUSAO'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dc9b87-7463-4520-bda0-b5d50e07c9d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filtrar os dados por presença, treineiro, EM e notas não-zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6446f930-8a59-4f09-a556-2abee3ada590",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processando 2014 com fraçao = 1% 2014 0.01\n",
      "87375\n",
      "filter data...\n",
      "45691\n"
     ]
    }
   ],
   "source": [
    "def filterdf(df):\n",
    "    df = df[df[\"TP_PRESENCA_CN\"] == 1]  # presente nas 4 provas\n",
    "    df = df[df[\"TP_PRESENCA_CH\"] == 1]\n",
    "    df = df[df[\"TP_PRESENCA_LC\"] == 1]\n",
    "    df = df[df[\"TP_PRESENCA_MT\"] == 1]\n",
    "    if \"IN_TREINEIRO\" in df.columns:\n",
    "        df = df[(df[\"IN_TREINEIRO\"] == 0) | (df[\"IN_TREINEIRO\"].isna())]  # não é treineiro ou não existe \n",
    "    df = df[df[\"TP_ST_CONCLUSAO\"].isin([1, 2])]  # afirma que concluiu ou vai concluir EM em 2019\n",
    "    # não queremos as notas == 0\n",
    "    df = df.query(\"NU_NOTA_CH != 0 and NU_NOTA_CN != 0 and NU_NOTA_LC != 0 and NU_NOTA_MT != 0\")\n",
    "    df.dropna(subset = ['TX_RESPOSTAS_CN','TX_RESPOSTAS_CH','TX_RESPOSTAS_LC','TX_RESPOSTAS_MT']) # achamos linhas com NaN para estas colunas!\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_data(ano,frac):\n",
    "    'carrega dados com determinado ano e fração'\n",
    "    print(f\"processando {ano} com fraçao = {frac*100:.0f}%\",ano, frac)\n",
    "    def skip(i,fraction=frac):\n",
    "        if i == 0:\n",
    "            return False  # precisamos manter o row=0 para ter o header\n",
    "        else:\n",
    "            return random.random() > fraction\n",
    "   \n",
    "    if ano == 2016:\n",
    "        caminho = f'../inep/enem/{ano}/DADOS/microdados_enem_{ano}.csv'\n",
    "    else:\n",
    "        caminho = f'../inep/enem/{ano}/DADOS/MICRODADOS_ENEM_{ano}.csv'\n",
    "    #print(caminho)\n",
    "    df = pd.read_csv(caminho,skiprows = skip, encoding='latin1',sep=\";\")\n",
    "    return df\n",
    "    \n",
    "def filter_data(df):\n",
    "    print(\"filter data...\")\n",
    "    return filterdf(df)\n",
    "\n",
    "def nome_do_arquivo(ano,frac):\n",
    "    frac = frac*100\n",
    "    fn = f'data/enem_{frac:.0f}_{ano}.csv'\n",
    "    return fn\n",
    "\n",
    "df = load_data(2014,0.01)\n",
    "print(len(df))\n",
    "df = filter_data(df)\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89522b81-3163-4311-9b65-2a2cb6a8a869",
   "metadata": {},
   "source": [
    "## Aqui faremos o trabalho de verdade\n",
    "Isso deve levar alguns minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f9c30-9fa0-498f-8e78-4ba6f89349ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processando 2009 com fraçao = 1% 2009 0.01\n",
      "filter data...\n",
      "processando 2010 com fraçao = 1% 2010 0.01\n",
      "filter data...\n",
      "processando 2011 com fraçao = 1% 2011 0.01\n",
      "filter data...\n",
      "processando 2012 com fraçao = 1% 2012 0.01\n",
      "filter data...\n",
      "processando 2013 com fraçao = 1% 2013 0.01\n",
      "filter data...\n",
      "processando 2014 com fraçao = 1% 2014 0.01\n",
      "filter data...\n",
      "processando 2015 com fraçao = 1% 2015 0.01\n",
      "filter data...\n",
      "processando 2016 com fraçao = 1% 2016 0.01\n"
     ]
    }
   ],
   "source": [
    "frac = 0.01\n",
    "for ano in range(2009,2023):\n",
    "    df = load_data(ano,frac)\n",
    "    df = filter_data(df)\n",
    "    fn = nome_do_arquivo(ano,frac)\n",
    "    #print(fn+\"...\\n\")\n",
    "    df.to_csv(fn,index=False)\n",
    "\n",
    "import inspect\n",
    "filter_conditions = inspect.getsource(filterdf)\n",
    "with open('data/filters.txt','w') as f:\n",
    "    f.write(filter_conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac28918d-87c8-4daf-a2a7-2d16d6cb4384",
   "metadata": {},
   "source": [
    "# Preparar os dados para análise TRI\n",
    "Precisamos converter as respostas e o gabarito no microdados do INEP para um formato que os pacotes de TRI conseguem ler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572307f-2323-4835-b37e-4eb87635eecb",
   "metadata": {},
   "source": [
    "## Funções para extrair acertos\n",
    "A maioria das análises TRI vão precisar de uma \"dicomitização\" das respostas. A estrutura de dados que vamos precisar é uma matriz com colunas itens e linhas pessoas com valores 0 e 1 para erros e acertos respectivamente.\n",
    "\n",
    "Vamos tentar criar umas funções que crie este estrutura de dados.\n",
    "\n",
    "\n",
    "Temos algumas informações sobre a estrutura dos microdados:\n",
    "* não vamos usar as primeiras 10 itens da prova LC (Linguágens e Códigos). Desde 2011 (?) estas posições são usadas para as questões de língua estrangeira (espanhol ou inglês). Acredito que somente 40 questões de LC são usados para criar a escala IRT desta prova.\n",
    "* O INEP divulga, desde o final de 2022, os parámetros IRT (discriminação, dificuldade e c). Além disso, dizem quais itens foram eliminados (\"pelo IRT\"), porque aparentemente atrapalharam a convergência da estimação do modelo IRT 3PL que estão usando. Vamos ter que tirar estes itens também.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bad554b-6f5e-45de-a7ea-7589eb5e183a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assumimos aqui que as planilhas com informações sobre os itens do INEP já foram convertidos para utf-8 e ficam no diretório DADOS\n",
    "def load_amostra(ano,perc):\n",
    "    df = pd.read_csv(f'data/enem_{perc}_{ano}.csv',dtype={'CO_PROVA_LC':int,'CO_PROVA_CN':int,'CO_PROVA_CH':int,'CO_PROVA_MT':int})\n",
    "    item_info = pd.read_csv(f'../inep/enem/{ano}/DADOS/ITENS_PROVA_{ano}-utf8.csv',sep='\\;',engine='python')\n",
    "    item_info.dropna(subset='CO_ITEM',inplace=True)\n",
    "    item_info['CO_ITEM'] = item_info['CO_ITEM'].astype(int)\n",
    "                     \n",
    "    #print(list(item_info.columns),'\\n')\n",
    "    #print(list(df.columns))\n",
    "    return df, item_info\n",
    "\n",
    "df, itens = load_amostra(2013,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f2631-e453-4333-bd37-48a1772034b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329e4e66-c6f8-4881-aaa9-e99c0e1ee796",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d644779-f98e-4f86-826f-70799aea8f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_acertos(s):\n",
    "    'resp e gab são strings, retorna uma lista'\n",
    "    resp = s.iloc[0]\n",
    "    gab = s.iloc[1]\n",
    "    return [r == g for r,g in zip(resp,gab)]\n",
    "\n",
    "def acertos_df(df,exame,as_int=True):\n",
    "    'Retorna dataframe com acertos. Colunas 1-45 = itens, Linhas = idx do df'\n",
    "    resp_col = 'TX_RESPOSTAS_' + exame\n",
    "    gab_col = 'TX_GABARITO_' + exame\n",
    "    adf = df[[resp_col,gab_col]].apply(to_acertos,axis=1,result_type = \"expand\")\n",
    "    adf['acertos'] = adf.sum(axis=1)\n",
    "    adf['caderno'] = df.loc[:,\"CO_PROVA_\" + exame]\n",
    "    if as_int:\n",
    "        adf = adf.astype(\"int\")\n",
    "    adf['nota_inep'] = df.loc[:,\"NU_NOTA_\" + exame]\n",
    "    return adf\n",
    "\n",
    "#item_info = pd.read_csv('data/ITENS_PROVA_2019-utf8.csv')\n",
    "\n",
    "def reorder_remove_cols(ac,item_info):\n",
    "    'takes a df with acertos, cuts it up and renames the columns for each caderno and stitches it back again.'\n",
    "    gb = ac.groupby(\"caderno\")\n",
    "    \n",
    "    itemgroups = item_info.groupby(\"CO_PROVA\")\n",
    "    cadernos = ac['caderno'].value_counts().index[:4] #only the 4 most used cadernos\n",
    "    groups = []\n",
    "    for caderno in cadernos:\n",
    "        #print(caderno)\n",
    "        itemnames = itemgroups.get_group(caderno).sort_values(\"CO_POSICAO\")[\"CO_ITEM\"].values\n",
    "        colmap = {i:j for i,j in zip(range(len(itemnames)),itemnames)}\n",
    "        group = gb.get_group(caderno).rename(colmap,axis=1)\n",
    "        groups.append(group)\n",
    "    ac = pd.concat(groups)\n",
    "    removed_items = item_info.query(\"IN_ITEM_ABAN == 1\")[\"CO_ITEM\"].unique()\n",
    "    ac = ac.drop(removed_items,axis=1,errors='ignore')\n",
    "    return ac\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e577959-2913-4a99-90a0-a2903bf16677",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = 1\n",
    "for ano in range(2014,2023):\n",
    "    df,itens = load_amostra(ano,perc)\n",
    "    for area in ['CH', 'CN', 'MT']: # LC tem o problema de 50 itens no gabarito\n",
    "        ac = acertos_df(df,area)\n",
    "        ac = reorder_remove_cols(ac,itens)\n",
    "        ac.to_csv(f'data/ac_{perc}_{ano}_{area}.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400849fe-22d8-4d77-9dda-8e676fce007d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
